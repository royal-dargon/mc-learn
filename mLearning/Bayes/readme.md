### 实验总结

> 这个实验算是第一次独立完成的机器学习的模型，从数据处理、数据编码、模型训练。相比于过去也是有了一点的进步吧！

#### 实验数据

实验数据选用的是树洞救援团提供的自杀风险监控。文件中的字段主要是自杀风险标签、编号、时间、昵称、文本内容、微博网址、所处的地址、出生生日或者是星座。我在做这个实验主要选用的数据就是纯文本呢的模态。希望用有监督学习的方式去解决问题。

#### 数据处理

在提取完文件中的字段后，我选择了对提取出来的数据进行随机的打乱，当然是建立在标签和数据一一对应的基础上。将百分之七十五的数据作为训练数据，剩下百分之二十五的数据则是作为测试数据。在数据编码方面，首先对标签进行编码化，具体的方法如下

```python
import sklearn.preprocessing as sp

lbe = sp.LabelEncoder()
y_lable = lbe.fit_transform(Y)
```

在训练的输入数据方面，则是需要将文本信息进行向量化。在这个实验中，我选择了先通过`jieba`分词的手段将文本信息进行分词的处理,这里会将一个文本分成很多的词。接下来，我选择使用停词表的手段，将出现在停词表的词语去除。然后提取出一个特征向量，我这里选择了1000作为维度。也就是说，如果我提取出来的特征词达到一千，便停止特征向量的增长。现在，也就是依照特征对文本进行向量化的处理。我这边是把特征向量中出现在文本的位置都标为1，将没有出现的位置标为0。

```python
train_features = [actions(feature_word, text) for text in x_train]
test_features = [actions(feature_word, text) for text in x_test]
```

这里其实可以很明显的发现得到向量实际上是很稀疏的。我想，这也是可以值得去优化的点。

#### 模型训练

在训练方面，我还是试过比较多的模型的，主要的方式函数`sklearn`提供的一些模型。主要是使用了贝叶斯系列和决策树系列，两个在调参的过程中，我目前得到最高准确率基本都是百分之八十五左右。

#### 未来方向

* 编码方面，想要尝试一个深度学习的手段，使用Bert的技术去编码
* 分类器算法方面，还是要多多尝试，未来可以试一下集成学习的手段
* 数据方面，当然是要考虑多模态的方向